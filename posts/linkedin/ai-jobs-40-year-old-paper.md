In 1983, a researcher named Lisbeth Bainbridge published a paper called "Ironies of Automation." It had nothing to do with AI.

But it might be the most relevant thing written about it.

Her argument: automation does not eliminate the need for expertise. It eliminates the opportunity to develop it. Humans get pushed into supervisory roles -- monitoring, approving, intervening when things break. They stop doing the actual work. And then when the system fails, they are still the ones expected to fix it.

That was about aviation and industrial control systems. Read it today and it sounds like a diagnosis of what is happening with GenAI in software, finance, and knowledge work in general.

We are not losing jobs. We are losing the reps. The slow, unglamorous practice that builds real understanding. And the accountability is not going anywhere.

I wrote a longer piece exploring this -- how it connects to software engineering, investing, and why the real risk is not displacement but the quiet erosion of expertise in systems we still depend on.

Link in comments.
